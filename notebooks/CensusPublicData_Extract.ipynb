{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbd5e520-1fe4-462b-b78f-326cec887c9e",
   "metadata": {},
   "source": [
    "# 1. Install libraries a/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8bf71a7c-5626-488a-bc01-2d15112e4184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries (uncomment and run if not already installed)\n",
    "# !pip install pandas neo4j\n",
    "# !pip install beautifulsoup4 lxml \n",
    "# !pip install requests tqdm\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c488fd2-68b3-47e5-90bf-82f5ba2a6f5c",
   "metadata": {},
   "source": [
    "## 2. Create Table of all unique survey IDs\n",
    "- The first step is to create our survey table\n",
    "- This will be the 'Central Table' for organizing all of our information\n",
    "\n",
    "### 2.1 Loading Census API Dataset info\n",
    "- File was obtained from `https://api.census.gov/data.html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "216e967d-0a05-4a9a-893d-d148565c50e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tables found: 1\n",
      "Headers: ['Title', 'Description', 'Vintage', 'Dataset Name', 'Dataset Type', 'Geography List', 'Variable List', 'Group List', 'SortList', 'Examples', 'Developer Documentation', 'API Base URL']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Dataset Type</th>\n",
       "      <th>Geography List</th>\n",
       "      <th>Variable List</th>\n",
       "      <th>Group List</th>\n",
       "      <th>SortList</th>\n",
       "      <th>Examples</th>\n",
       "      <th>Developer Documentation</th>\n",
       "      <th>API Base URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1648 datasets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1986 County Business Patterns: Business Patterns</td>\n",
       "      <td>County Business Patterns (CBP) is an annual se...</td>\n",
       "      <td>1986</td>\n",
       "      <td>cbp</td>\n",
       "      <td>Aggregate</td>\n",
       "      <td>http://api.census.gov/data/1986/cbp/geography....</td>\n",
       "      <td>http://api.census.gov/data/1986/cbp/variables....</td>\n",
       "      <td>http://api.census.gov/data/1986/cbp/groups.html</td>\n",
       "      <td>http://api.census.gov/data/1986/cbp/sorts.html</td>\n",
       "      <td>http://api.census.gov/data/1986/cbp/examples.html</td>\n",
       "      <td>http://www.census.gov/developer/</td>\n",
       "      <td>http://api.census.gov/data/1986/cbp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1987 County Business Patterns: Business Patterns</td>\n",
       "      <td>County Business Patterns (CBP) is an annual se...</td>\n",
       "      <td>1987</td>\n",
       "      <td>cbp</td>\n",
       "      <td>Aggregate</td>\n",
       "      <td>http://api.census.gov/data/1987/cbp/geography....</td>\n",
       "      <td>http://api.census.gov/data/1987/cbp/variables....</td>\n",
       "      <td>http://api.census.gov/data/1987/cbp/groups.html</td>\n",
       "      <td>http://api.census.gov/data/1987/cbp/sorts.html</td>\n",
       "      <td>http://api.census.gov/data/1987/cbp/examples.html</td>\n",
       "      <td>http://www.census.gov/developer/</td>\n",
       "      <td>http://api.census.gov/data/1987/cbp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1988 County Business Patterns: Business Patterns</td>\n",
       "      <td>County Business Patterns (CBP) is an annual se...</td>\n",
       "      <td>1988</td>\n",
       "      <td>cbp</td>\n",
       "      <td>Aggregate</td>\n",
       "      <td>http://api.census.gov/data/1988/cbp/geography....</td>\n",
       "      <td>http://api.census.gov/data/1988/cbp/variables....</td>\n",
       "      <td>http://api.census.gov/data/1988/cbp/groups.html</td>\n",
       "      <td>http://api.census.gov/data/1988/cbp/sorts.html</td>\n",
       "      <td>http://api.census.gov/data/1988/cbp/examples.html</td>\n",
       "      <td>http://www.census.gov/developer/</td>\n",
       "      <td>http://api.census.gov/data/1988/cbp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1989 County Business Patterns: Business Patterns</td>\n",
       "      <td>County Business Patterns (CBP) is an annual se...</td>\n",
       "      <td>1989</td>\n",
       "      <td>cbp</td>\n",
       "      <td>Aggregate</td>\n",
       "      <td>http://api.census.gov/data/1989/cbp/geography....</td>\n",
       "      <td>http://api.census.gov/data/1989/cbp/variables....</td>\n",
       "      <td>http://api.census.gov/data/1989/cbp/groups.html</td>\n",
       "      <td>http://api.census.gov/data/1989/cbp/sorts.html</td>\n",
       "      <td>http://api.census.gov/data/1989/cbp/examples.html</td>\n",
       "      <td>http://www.census.gov/developer/</td>\n",
       "      <td>http://api.census.gov/data/1989/cbp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Title  \\\n",
       "0                                     1648 datasets   \n",
       "1  1986 County Business Patterns: Business Patterns   \n",
       "2  1987 County Business Patterns: Business Patterns   \n",
       "3  1988 County Business Patterns: Business Patterns   \n",
       "4  1989 County Business Patterns: Business Patterns   \n",
       "\n",
       "                                         Description Vintage Dataset Name  \\\n",
       "0                                                NaN     NaN          NaN   \n",
       "1  County Business Patterns (CBP) is an annual se...    1986          cbp   \n",
       "2  County Business Patterns (CBP) is an annual se...    1987          cbp   \n",
       "3  County Business Patterns (CBP) is an annual se...    1988          cbp   \n",
       "4  County Business Patterns (CBP) is an annual se...    1989          cbp   \n",
       "\n",
       "  Dataset Type                                     Geography List  \\\n",
       "0          NaN                                                NaN   \n",
       "1    Aggregate  http://api.census.gov/data/1986/cbp/geography....   \n",
       "2    Aggregate  http://api.census.gov/data/1987/cbp/geography....   \n",
       "3    Aggregate  http://api.census.gov/data/1988/cbp/geography....   \n",
       "4    Aggregate  http://api.census.gov/data/1989/cbp/geography....   \n",
       "\n",
       "                                       Variable List  \\\n",
       "0                                                NaN   \n",
       "1  http://api.census.gov/data/1986/cbp/variables....   \n",
       "2  http://api.census.gov/data/1987/cbp/variables....   \n",
       "3  http://api.census.gov/data/1988/cbp/variables....   \n",
       "4  http://api.census.gov/data/1989/cbp/variables....   \n",
       "\n",
       "                                        Group List  \\\n",
       "0                                              NaN   \n",
       "1  http://api.census.gov/data/1986/cbp/groups.html   \n",
       "2  http://api.census.gov/data/1987/cbp/groups.html   \n",
       "3  http://api.census.gov/data/1988/cbp/groups.html   \n",
       "4  http://api.census.gov/data/1989/cbp/groups.html   \n",
       "\n",
       "                                         SortList  \\\n",
       "0                                             NaN   \n",
       "1  http://api.census.gov/data/1986/cbp/sorts.html   \n",
       "2  http://api.census.gov/data/1987/cbp/sorts.html   \n",
       "3  http://api.census.gov/data/1988/cbp/sorts.html   \n",
       "4  http://api.census.gov/data/1989/cbp/sorts.html   \n",
       "\n",
       "                                            Examples  \\\n",
       "0                                                NaN   \n",
       "1  http://api.census.gov/data/1986/cbp/examples.html   \n",
       "2  http://api.census.gov/data/1987/cbp/examples.html   \n",
       "3  http://api.census.gov/data/1988/cbp/examples.html   \n",
       "4  http://api.census.gov/data/1989/cbp/examples.html   \n",
       "\n",
       "            Developer Documentation                         API Base URL  \n",
       "0                               NaN                                  NaN  \n",
       "1  http://www.census.gov/developer/  http://api.census.gov/data/1986/cbp  \n",
       "2  http://www.census.gov/developer/  http://api.census.gov/data/1987/cbp  \n",
       "3  http://www.census.gov/developer/  http://api.census.gov/data/1988/cbp  \n",
       "4  http://www.census.gov/developer/  http://api.census.gov/data/1989/cbp  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the path to your HTML file\n",
    "html_file_path = './data/CensusDataAPI_data.html'  # Update this path as needed\n",
    "\n",
    "# Define the columns that contain URLs\n",
    "url_columns = [\n",
    "    'Geography List',\n",
    "    'Variable List',\n",
    "    'Group List',\n",
    "    'SortList',\n",
    "    'Examples',\n",
    "    'Developer Documentation',\n",
    "    'API Base URL'\n",
    "]\n",
    "\n",
    "# Load and parse the HTML file\n",
    "with open(html_file_path, 'r', encoding='utf-8') as file:\n",
    "    soup = BeautifulSoup(file, 'lxml')\n",
    "\n",
    "# Find all tables in the HTML\n",
    "tables = soup.find_all('table')\n",
    "print(f\"Number of tables found: {len(tables)}\")\n",
    "\n",
    "# Check if at least one table is found\n",
    "if not tables:\n",
    "    raise ValueError(\"No tables found in the HTML file.\")\n",
    "\n",
    "# Assuming your data is in the first table; adjust the index if necessary\n",
    "table = tables[0]\n",
    "\n",
    "# Extract table headers\n",
    "headers = [th.get_text(strip=True) for th in table.find_all('th')]\n",
    "print(f\"Headers: {headers}\")\n",
    "\n",
    "# Initialize a list to store each row's data\n",
    "rows = []\n",
    "\n",
    "# Iterate over each row in the table (skip header row)\n",
    "for tr in table.find_all('tr')[1:]:\n",
    "    cells = tr.find_all(['td', 'th'])\n",
    "    row_data = {}\n",
    "    for idx, cell in enumerate(cells):\n",
    "        # Get the header for the current cell\n",
    "        header = headers[idx] if idx < len(headers) else f'Column_{idx+1}'\n",
    "\n",
    "        if header in url_columns:\n",
    "            # Extract all href attributes from <a> tags\n",
    "            links = cell.find_all('a')\n",
    "            urls = [link.get('href') for link in links if link.get('href')]\n",
    "\n",
    "            # If no <a> tags, check if the cell contains a plain URL\n",
    "            if not urls:\n",
    "                cell_text = cell.get_text(strip=True)\n",
    "                if cell_text.startswith('http://') or cell_text.startswith('https://'):\n",
    "                    urls = [cell_text]\n",
    "\n",
    "            # Join multiple URLs with '; ' or set as None if no URLs found\n",
    "            row_data[header] = '; '.join(urls) if urls else None\n",
    "        else:\n",
    "            # For other columns, store the text\n",
    "            row_data[header] = cell.get_text(strip=True)\n",
    "    rows.append(row_data)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df_census = pd.DataFrame(rows)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df_census.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee50096-e7b0-489e-ad4e-d03611c762ec",
   "metadata": {},
   "source": [
    "### 2.2 Parsing data set name column\n",
    "- There is hierarchial information embedded in this column, potenially use for the graph database createion\n",
    "- However, just in case, we're going to extract that, and grab the 'month' as time data we may want to use as a relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0f9a9675-5256-4612-bb90-eb8196400b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survey</th>\n",
       "      <th>Subtype1</th>\n",
       "      <th>Subtype2</th>\n",
       "      <th>Subtype3</th>\n",
       "      <th>Vintage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cbp</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cbp</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cbp</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cbp</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cps</td>\n",
       "      <td>basic</td>\n",
       "      <td>apr</td>\n",
       "      <td>None</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cps</td>\n",
       "      <td>basic</td>\n",
       "      <td>aug</td>\n",
       "      <td>None</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Survey Subtype1 Subtype2 Subtype3 Vintage\n",
       "0    NaN      NaN      NaN      NaN     NaN\n",
       "1    cbp     None     None     None    1986\n",
       "2    cbp     None     None     None    1987\n",
       "3    cbp     None     None     None    1988\n",
       "4    cbp     None     None     None    1989\n",
       "5    cps    basic      apr     None    1989\n",
       "6    cps    basic      aug     None    1989"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the delimiter used in the \"Dataset Name\" column\n",
    "delimiter = '›'\n",
    "\n",
    "# Split the \"Dataset Name\" into hierarchical levels, maximum of 3 splits (4 parts)\n",
    "hierarchy_split = df_census['Dataset Name'].str.split(delimiter, n=3, expand=True)\n",
    "\n",
    "# Rename the new columns based on hierarchy levels\n",
    "hierarchy_split = hierarchy_split.rename(columns={\n",
    "    0: 'Survey',\n",
    "    1: 'Subtype1',\n",
    "    2: 'Subtype2',\n",
    "    3: 'Subtype3'\n",
    "})\n",
    "\n",
    "# Concatenate the new hierarchy columns with the original DataFrame\n",
    "df_census = pd.concat([df_census, hierarchy_split], axis=1)\n",
    "\n",
    "# Display the first few rows after parsing\n",
    "df_census[['Survey', 'Subtype1', 'Subtype2', 'Subtype3', 'Vintage']].head(7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517eb64b-576f-4c3f-91b3-bacc7c1c4254",
   "metadata": {},
   "source": [
    "### 2.3 Extract Month from subtype columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2d717132-2b9b-4515-b489-e1a243b1274d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survey</th>\n",
       "      <th>Subtype1</th>\n",
       "      <th>Subtype2</th>\n",
       "      <th>Subtype3</th>\n",
       "      <th>Month</th>\n",
       "      <th>Vintage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cbp</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cbp</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cbp</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cbp</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Survey Subtype1 Subtype2 Subtype3 Month Vintage\n",
       "0    NaN      NaN      NaN      NaN  None     NaN\n",
       "1    cbp     None     None     None  None    1986\n",
       "2    cbp     None     None     None  None    1987\n",
       "3    cbp     None     None     None  None    1988\n",
       "4    cbp     None     None     None  None    1989"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a list of month abbreviations for identification (lowercase for matching)\n",
    "months = ['jan', 'feb', 'mar', 'apr', 'may', 'jun',\n",
    "          'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "\n",
    "# Function to identify and extract month from subtype columns\n",
    "def extract_month(row):\n",
    "    for subtype_col in ['Subtype1', 'Subtype2', 'Subtype3']:\n",
    "        if pd.notnull(row[subtype_col]):\n",
    "            if row[subtype_col].strip().lower() in months:\n",
    "                return row[subtype_col].strip().capitalize()\n",
    "    return None\n",
    "\n",
    "# Apply the function to create a new 'Month' column\n",
    "df_census['Month'] = df_census.apply(extract_month, axis=1)\n",
    "\n",
    "# Remove the month from the subtype columns to avoid duplication\n",
    "for subtype_col in ['Subtype1', 'Subtype2', 'Subtype3']:\n",
    "    df_census[subtype_col] = df_census[subtype_col].apply(\n",
    "        lambda x: None if pd.notnull(x) and x.strip().lower() in months else x\n",
    "    )\n",
    "\n",
    "# Display the first few rows after extracting 'Month'\n",
    "df_census[['Survey', 'Subtype1', 'Subtype2', 'Subtype3', 'Month', 'Vintage']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b3a4c6-d68e-4eb5-a44d-ae7d49e114a4",
   "metadata": {},
   "source": [
    "### 2.4 Get a unique ID for each row\n",
    "1. Use the identifier from the API URL which is a JSON file that contains a unique identifier (aka KEY) for each dataset.\n",
    "2. Why Use identifier as the Key:\n",
    "- Uniqueness: The identifier provides a unique reference for each dataset, ensuring there are no duplicates.\n",
    "- Consistency: Using a standardized key helps in linking data across different sources and maintaining data integrity within your knowledge graph.\n",
    "- Efficiency: It simplifies data retrieval and relationships within the knowledge graph.\n",
    "\n",
    "#### 2.4.1 First, drop the first row contains the number of records and a bunch of na values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "330aeb88-3d11-48ff-a491-005304762ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropping row:\n",
      "           Title Description Vintage Dataset Name Dataset Type Geography List  \\\n",
      "0  1648 datasets         NaN     NaN          NaN          NaN            NaN   \n",
      "\n",
      "  Variable List Group List SortList Examples Developer Documentation  \\\n",
      "0           NaN        NaN      NaN      NaN                     NaN   \n",
      "\n",
      "  API Base URL Survey Subtype1 Subtype2 Subtype3 Month identifier id_name  \n",
      "0          NaN    NaN      NaN      NaN      NaN  None       None    None  \n",
      "\n",
      "After dropping row:\n",
      "                                              Title  \\\n",
      "0  1986 County Business Patterns: Business Patterns   \n",
      "\n",
      "                                         Description Vintage Dataset Name  \\\n",
      "0  County Business Patterns (CBP) is an annual se...    1986          cbp   \n",
      "\n",
      "  Dataset Type                                     Geography List  \\\n",
      "0    Aggregate  http://api.census.gov/data/1986/cbp/geography....   \n",
      "\n",
      "                                       Variable List  \\\n",
      "0  http://api.census.gov/data/1986/cbp/variables....   \n",
      "\n",
      "                                        Group List  \\\n",
      "0  http://api.census.gov/data/1986/cbp/groups.html   \n",
      "\n",
      "                                         SortList  \\\n",
      "0  http://api.census.gov/data/1986/cbp/sorts.html   \n",
      "\n",
      "                                            Examples  \\\n",
      "0  http://api.census.gov/data/1986/cbp/examples.html   \n",
      "\n",
      "            Developer Documentation                         API Base URL  \\\n",
      "0  http://www.census.gov/developer/  http://api.census.gov/data/1986/cbp   \n",
      "\n",
      "  Survey Subtype1 Subtype2 Subtype3 Month  \\\n",
      "0    cbp     None     None     None  None   \n",
      "\n",
      "                              identifier  id_name  \n",
      "0  http://api.census.gov/data/id/CBP1986  CBP1986  \n"
     ]
    }
   ],
   "source": [
    "# Removeing first row where all elements are NaN\n",
    "# Before removing first row\n",
    "print(\"Before dropping row:\")\n",
    "print(df_census.head(1))\n",
    "\n",
    "# Removing first row\n",
    "df_census = df_census.drop(0).reset_index(drop=True)\n",
    "\n",
    "# After removing first row\n",
    "print(\"\\nAfter dropping row:\")\n",
    "print(df_census.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee787fc-9818-48b4-95d1-734e503b32d0",
   "metadata": {},
   "source": [
    "#### 2.4.2 Extracting the Identifier Field to create key column SurveyID\n",
    "- Robust error handling was added do account for network issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8a2e6706-6bbb-4cae-b8b8-77c54b88e52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current DataFrame Columns:\n",
      "['Title', 'Description', 'Vintage', 'Dataset Name', 'Dataset Type', 'Geography List', 'Variable List', 'Group List', 'SortList', 'Examples', 'Developer Documentation', 'API Base URL', 'Survey', 'Subtype1', 'Subtype2', 'Subtype3', 'Month', 'identifier', 'id_name']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching identifiers: 100%|█████████████████| 1648/1648 [02:27<00:00, 11.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After extracting 'identifier' and 'SurveyID':\n",
      "  Survey Subtype1 Subtype2 Subtype3 Vintage  \\\n",
      "0    cbp     None     None     None    1986   \n",
      "1    cbp     None     None     None    1987   \n",
      "2    cbp     None     None     None    1988   \n",
      "3    cbp     None     None     None    1989   \n",
      "4    cps    basic     None     None    1989   \n",
      "\n",
      "                                      identifier        SurveyID  \n",
      "0          http://api.census.gov/data/id/CBP1986         CBP1986  \n",
      "1          http://api.census.gov/data/id/CBP1987         CBP1987  \n",
      "2          http://api.census.gov/data/id/CBP1988         CBP1988  \n",
      "3          http://api.census.gov/data/id/CBP1989         CBP1989  \n",
      "4  https://api.census.gov/data/id/CPSBASIC198904  CPSBASIC198904  \n",
      "\n",
      "Number of missing identifiers: 0\n",
      "All identifiers were successfully extracted.\n",
      "\n",
      "Updated DataFrame with 'identifier' and 'SurveyID' successfully saved to ./data/df_census_with_identifiers.csv\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  # For progress bar\n",
    "\n",
    "# Remove rows where all elements are NaN\n",
    "df_census.dropna(how='all', inplace=True)\n",
    "df_census.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display current DataFrame columns to confirm\n",
    "print(\"Current DataFrame Columns:\")\n",
    "print(df_census.columns.tolist())\n",
    "\n",
    "# Step 1: Set up a session with retries (move this outside the function)\n",
    "session = requests.Session()\n",
    "retries = Retry(\n",
    "    total=5,  # Total number of retries\n",
    "    backoff_factor=1,  # Time to wait between retries (exponential backoff)\n",
    "    status_forcelist=[500, 502, 503, 504],  # Retry on these HTTP status codes\n",
    "    allowed_methods=['GET']  # Use 'allowed_methods' instead of 'method_whitelist'\n",
    ")\n",
    "adapter = HTTPAdapter(max_retries=retries)\n",
    "session.mount('http://', adapter)\n",
    "session.mount('https://', adapter)\n",
    "\n",
    "# Step 2: Define a Function to Extract 'identifier' and 'SurveyID' from a Single URL with Retries\n",
    "\n",
    "def extract_identifier(url, session):\n",
    "    \"\"\"\n",
    "    Fetches JSON data from the given URL and extracts the 'identifier' and 'SurveyID'.\n",
    "    \n",
    "    Parameters:\n",
    "        url (str): The API Base URL pointing to the JSON file.\n",
    "        session (requests.Session): The session object with retry strategy.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (identifier, SurveyID) where:\n",
    "               - identifier (str or None): The full identifier URL.\n",
    "               - SurveyID (str or None): The part of the identifier after '/id/'.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure the URL is a valid string\n",
    "        if not isinstance(url, str) or pd.isna(url):\n",
    "            print(\"Invalid URL encountered.\")\n",
    "            return None, None\n",
    "\n",
    "        # Fetch the JSON data from the URL\n",
    "        response = session.get(url, timeout=10)\n",
    "        response.raise_for_status()  # Raise an error for bad status codes\n",
    "        json_data = response.json()\n",
    "        \n",
    "        # Extract the 'identifier' field from the first dataset\n",
    "        dataset_list = json_data.get('dataset', [])\n",
    "        if isinstance(dataset_list, list) and len(dataset_list) > 0:\n",
    "            identifier = dataset_list[0].get('identifier', None)\n",
    "        else:\n",
    "            identifier = None\n",
    "        \n",
    "        # Extract the 'SurveyID' by splitting the 'identifier' at '/id/'\n",
    "        if identifier and '/id/' in identifier:\n",
    "            SurveyID = identifier.split('/id/')[-1]\n",
    "        else:\n",
    "            SurveyID = None\n",
    "        \n",
    "        return identifier, SurveyID\n",
    "    \n",
    "    except requests.exceptions.Timeout:\n",
    "        print(f\"Timeout error occurred while fetching {url}\")\n",
    "        return None, None\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(f\"Connection error occurred while fetching {url}\")\n",
    "        return None, None\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"HTTP error occurred while fetching {url}: {e}\")\n",
    "        return None, None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error occurred while fetching {url}: {e}\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while processing {url}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Step 3: Apply the Extraction Function to All Rows\n",
    "\n",
    "# Initialize lists to store the results\n",
    "identifiers = []\n",
    "survey_ids = []\n",
    "\n",
    "# Iterate over each API Base URL and extract identifiers\n",
    "for url in tqdm(df_census['API Base URL'], desc=\"Fetching identifiers\"):\n",
    "    identifier, SurveyID = extract_identifier(url, session)\n",
    "    identifiers.append(identifier)\n",
    "    survey_ids.append(SurveyID)\n",
    "\n",
    "# Step 4: Add the Extracted Data to the DataFrame\n",
    "\n",
    "df_census['identifier'] = identifiers\n",
    "df_census['SurveyID'] = survey_ids\n",
    "\n",
    "# Display the first few rows to verify the extraction\n",
    "print(\"\\nAfter extracting 'identifier' and 'SurveyID':\")\n",
    "print(df_census[['Survey', 'Subtype1', 'Subtype2', 'Subtype3', 'Vintage', 'identifier', 'SurveyID']].head())\n",
    "\n",
    "# Step 5: Handle Missing Identifiers\n",
    "\n",
    "# Check for missing identifiers\n",
    "missing_identifiers = df_census['identifier'].isnull().sum()\n",
    "print(f\"\\nNumber of missing identifiers: {missing_identifiers}\")\n",
    "\n",
    "# If there are missing identifiers, display them and save to a separate CSV for manual correction\n",
    "if missing_identifiers > 0:\n",
    "    print(\"\\nRows with missing identifiers:\")\n",
    "    missing_identifiers_df = df_census[df_census['identifier'].isnull()]\n",
    "    print(missing_identifiers_df[['Survey', 'API Base URL']].head())\n",
    "    \n",
    "    # Save these rows to a separate CSV file\n",
    "    missing_identifiers_df.to_csv('./data/missing_identifiers.csv', index=False)\n",
    "    print(\"\\nSaved rows with missing identifiers to 'missing_identifiers.csv' for manual correction.\")\n",
    "else:\n",
    "    print(\"All identifiers were successfully extracted.\")\n",
    "\n",
    "# Step 6: Save the Updated DataFrame for Backup\n",
    "\n",
    "# Save the updated DataFrame to a CSV file\n",
    "output_file = './data/df_census_with_identifiers.csv'\n",
    "df_census.to_csv(output_file, index=False)\n",
    "print(f\"\\nUpdated DataFrame with 'identifier' and 'SurveyID' successfully saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b451ae55-8985-4c4e-84f7-f25c1d8c9086",
   "metadata": {},
   "source": [
    "#### 2.4.3 Manually fixing errors (Only if needed)\n",
    "- Recommended: Rerun! Maybe wait if there is a network issue.\n",
    "- Manualy fixing is an acceptable strategy, but prone to human error.\n",
    "- robust error handling was added to avoid errors, but stuff happens.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69656f8f-acf7-4ab0-87f9-6edfbc3b12cf",
   "metadata": {},
   "source": [
    "## 3. Create External Tables and Linkages for Survey Table\n",
    "1. Several columns have URLs that link to other tables: 'Geography List', 'Variable List', 'Group List', 'SortList', 'Examples'\n",
    "2. In order to avoid issues with data scraping, collect a copy of the data with linkages back to SurveyID\n",
    "3. Variables and Group have more complex structures that will require additional processing to capture the information\n",
    "4. 'SortList' is believed to be a parameter and probably doesn't have any info, but we'll look anyways\n",
    "\n",
    "> We will programatically create the graph database from these tables. The CSV files are an intermediary step, but one done out of practical necessity to avoid retrieval issues and create a solid foundation to work from with all data local to the compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a301e268-cc51-4330-ad89-927f1eef9420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff3fa5d-762f-476b-ba5e-98701af3f018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fb9cb4-e862-47f0-af7f-cf9da5ca5b2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562e4b45-a296-4041-9bdd-f9eb496dffb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe411f6-3eb7-4848-b59b-bd7d97f99b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa056e1-2a82-41da-bd8d-8ad4a3b90d19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1009e8d1-6983-4df1-9fcb-7176ed818332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing identifier extraction with URL: http://api.census.gov/data/1986/cbp\n",
      "\n",
      "Fetched JSON data:\n",
      "{'@context': 'https://project-open-data.cio.gov/v1.1/schema/catalog.jsonld',\n",
      " '@id': 'http://api.census.gov/data/1986/cbp.json',\n",
      " '@type': 'dcat:Catalog',\n",
      " 'conformsTo': 'https://project-open-data.cio.gov/v1.1/schema',\n",
      " 'dataset': [{'@type': 'dcat:Dataset',\n",
      "              'accessLevel': 'public',\n",
      "              'bureauCode': ['006:07'],\n",
      "              'c_dataset': ['cbp'],\n",
      "              'c_documentationLink': 'http://www.census.gov/developer/',\n",
      "              'c_examplesLink': 'http://api.census.gov/data/1986/cbp/examples.json',\n",
      "              'c_geographyLink': 'http://api.census.gov/data/1986/cbp/geography.json',\n",
      "              'c_groupsLink': 'http://api.census.gov/data/1986/cbp/groups.json',\n",
      "              'c_isAggregate': True,\n",
      "              'c_isAvailable': True,\n",
      "              'c_sorts_url': 'http://api.census.gov/data/1986/cbp/sorts.json',\n",
      "              'c_tagsLink': 'http://api.census.gov/data/1986/cbp/tags.json',\n",
      "              'c_variablesLink': 'http://api.census.gov/data/1986/cbp/variables.json',\n",
      "              'c_vintage': 1986,\n",
      "              'contactPoint': {'fn': 'CBP Staff',\n",
      "                               'hasEmail': 'mailto:ewd.county.business.patterns@census.gov'},\n",
      "              'description': 'County Business Patterns (CBP) is an annual '\n",
      "                             'series that provides economic data by industry '\n",
      "                             'at the U.S., State, County and Metropolitan Area '\n",
      "                             'levels. This series includes the number of '\n",
      "                             'establishments, employment during the week of '\n",
      "                             'March 12, first quarter payroll, and annual '\n",
      "                             'payroll. CBP provides statistics for businesses '\n",
      "                             'with paid employees for the U.S., Puerto Rico, '\n",
      "                             'and the Island Areas. Census Bureau staff '\n",
      "                             'identified a processing error that affects '\n",
      "                             'selected data from the 2014 County Business '\n",
      "                             'Patterns (CBP). As a result, we suppressed 2014 '\n",
      "                             'employment and payroll totals in the Health Care '\n",
      "                             'and Social Assistance sector (Sector 62) for the '\n",
      "                             'following geographies: U.S.; Michigan; Battle '\n",
      "                             'Creek, MI metro area; Calhoun County, MI; and '\n",
      "                             'the 3rd congressional district of Michigan. This '\n",
      "                             'processing error did not affect other sectors. '\n",
      "                             'While suppressed values can be derived by '\n",
      "                             'subtraction, we do not recommend using the '\n",
      "                             'derived values in any analyses.  The Census '\n",
      "                             'Bureau plans to release revised statistics at a '\n",
      "                             'later date.',\n",
      "              'distribution': [{'@type': 'dcat:Distribution',\n",
      "                                'accessURL': 'http://api.census.gov/data/1986/cbp',\n",
      "                                'description': 'API endpoint',\n",
      "                                'format': 'API',\n",
      "                                'mediaType': 'application/json',\n",
      "                                'title': 'API endpoint'}],\n",
      "              'identifier': 'http://api.census.gov/data/id/CBP1986',\n",
      "              'keyword': ['census'],\n",
      "              'license': 'http://creativecommons.org/publicdomain/zero/1.0/',\n",
      "              'modified': '2019-02-13',\n",
      "              'programCode': ['006:007'],\n",
      "              'publisher': {'@type': 'org:Organization',\n",
      "                            'name': 'U.S. Census Bureau',\n",
      "                            'subOrganizationOf': {'@type': 'org:Organization',\n",
      "                                                  'name': 'U.S. Department Of '\n",
      "                                                          'Commerce',\n",
      "                                                  'subOrganizationOf': {'@type': 'org:Organization',\n",
      "                                                                        'name': 'U.S. '\n",
      "                                                                                'Government'}}},\n",
      "              'references': ['http://www.census.gov/developers/'],\n",
      "              'spatial': 'United States',\n",
      "              'temporal': '1986/1986',\n",
      "              'title': '1986 County Business Patterns: Business Patterns'}],\n",
      " 'describedBy': 'https://project-open-data.cio.gov/v1.1/schema/catalog.json'}\n",
      "\n",
      "Extracted identifier: http://api.census.gov/data/id/CBP1986\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139f70fb-5e9f-4d8e-9a8b-ac4a1318d579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7c7eea-74e2-4971-843f-4afbeb72c1c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ee4599-ed59-4a4e-8428-17b7681ae9f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44fc4983-5f45-45d1-a97a-8bb1cc290cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets Metadata Loaded:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>identifier</th>\n",
       "      <th>contact</th>\n",
       "      <th>access_level</th>\n",
       "      <th>modified</th>\n",
       "      <th>publisher</th>\n",
       "      <th>references</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cps</td>\n",
       "      <td>1994</td>\n",
       "      <td>Jun 1994 Current Population Survey: Basic Monthly</td>\n",
       "      <td>To provide estimates of employment, unemployme...</td>\n",
       "      <td>https://api.census.gov/data/id/CPSBASIC199406</td>\n",
       "      <td>CPS Staff</td>\n",
       "      <td>public</td>\n",
       "      <td>2019-10-09 15:05:36.0</td>\n",
       "      <td>U.S. Census Bureau</td>\n",
       "      <td>https://www.census.gov/developers/</td>\n",
       "      <td>census</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset_name  year                                              title  \\\n",
       "0          cps  1994  Jun 1994 Current Population Survey: Basic Monthly   \n",
       "\n",
       "                                         description  \\\n",
       "0  To provide estimates of employment, unemployme...   \n",
       "\n",
       "                                      identifier    contact access_level  \\\n",
       "0  https://api.census.gov/data/id/CPSBASIC199406  CPS Staff       public   \n",
       "\n",
       "                modified           publisher  \\\n",
       "0  2019-10-09 15:05:36.0  U.S. Census Bureau   \n",
       "\n",
       "                           references keywords  \n",
       "0  https://www.census.gov/developers/   census  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables Metadata for 1980s Loaded:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>variable_name</th>\n",
       "      <th>label</th>\n",
       "      <th>concept</th>\n",
       "      <th>predicateType</th>\n",
       "      <th>group</th>\n",
       "      <th>limit</th>\n",
       "      <th>attributes</th>\n",
       "      <th>decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbp</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986 County Business Patterns: Business Patterns</td>\n",
       "      <td>for</td>\n",
       "      <td>Census API FIPS 'for' clause</td>\n",
       "      <td>Census API Geography Specification</td>\n",
       "      <td>fips-for</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset_name  year                                             title  \\\n",
       "0          cbp  1986  1986 County Business Patterns: Business Patterns   \n",
       "\n",
       "  variable_name                         label  \\\n",
       "0           for  Census API FIPS 'for' clause   \n",
       "\n",
       "                              concept predicateType  group  limit  attributes  \\\n",
       "0  Census API Geography Specification      fips-for    NaN      0         NaN   \n",
       "\n",
       "  decade  \n",
       "0  1980s  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables Metadata for 1990s Loaded:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>variable_name</th>\n",
       "      <th>label</th>\n",
       "      <th>concept</th>\n",
       "      <th>predicateType</th>\n",
       "      <th>group</th>\n",
       "      <th>limit</th>\n",
       "      <th>attributes</th>\n",
       "      <th>decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cps/basic/jun</td>\n",
       "      <td>1994</td>\n",
       "      <td>Jun 1994 Current Population Survey: Basic Monthly</td>\n",
       "      <td>for</td>\n",
       "      <td>Census API FIPS 'for' clause</td>\n",
       "      <td>Census API Geography Specification</td>\n",
       "      <td>fips-for</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1990s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset_name  year                                              title  \\\n",
       "0  cps/basic/jun  1994  Jun 1994 Current Population Survey: Basic Monthly   \n",
       "\n",
       "  variable_name                         label  \\\n",
       "0           for  Census API FIPS 'for' clause   \n",
       "\n",
       "                              concept predicateType  group  limit  attributes  \\\n",
       "0  Census API Geography Specification      fips-for    NaN      0         NaN   \n",
       "\n",
       "  decade  \n",
       "0  1990s  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables Metadata for 2000s Loaded:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>variable_name</th>\n",
       "      <th>label</th>\n",
       "      <th>concept</th>\n",
       "      <th>predicateType</th>\n",
       "      <th>group</th>\n",
       "      <th>limit</th>\n",
       "      <th>attributes</th>\n",
       "      <th>decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbp</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000 County Business Patterns: Business Patterns</td>\n",
       "      <td>for</td>\n",
       "      <td>Census API FIPS 'for' clause</td>\n",
       "      <td>Census API Geography Specification</td>\n",
       "      <td>fips-for</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset_name  year                                             title  \\\n",
       "0          cbp  2000  2000 County Business Patterns: Business Patterns   \n",
       "\n",
       "  variable_name                         label  \\\n",
       "0           for  Census API FIPS 'for' clause   \n",
       "\n",
       "                              concept predicateType group  limit attributes  \\\n",
       "0  Census API Geography Specification      fips-for   NaN      0        NaN   \n",
       "\n",
       "  decade  \n",
       "0  2000s  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables Metadata for 2010s Loaded:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>variable_name</th>\n",
       "      <th>label</th>\n",
       "      <th>concept</th>\n",
       "      <th>predicateType</th>\n",
       "      <th>group</th>\n",
       "      <th>limit</th>\n",
       "      <th>attributes</th>\n",
       "      <th>decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbp</td>\n",
       "      <td>2012</td>\n",
       "      <td>Annual Economic Surveys: Business Patterns: Co...</td>\n",
       "      <td>for</td>\n",
       "      <td>Census API FIPS 'for' clause</td>\n",
       "      <td>Census API Geography Specification</td>\n",
       "      <td>fips-for</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset_name  year                                              title  \\\n",
       "0          cbp  2012  Annual Economic Surveys: Business Patterns: Co...   \n",
       "\n",
       "  variable_name                         label  \\\n",
       "0           for  Census API FIPS 'for' clause   \n",
       "\n",
       "                              concept predicateType group  limit attributes  \\\n",
       "0  Census API Geography Specification      fips-for   NaN      0        NaN   \n",
       "\n",
       "  decade  \n",
       "0  2010s  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables Metadata for 2020s Loaded:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>variable_name</th>\n",
       "      <th>label</th>\n",
       "      <th>concept</th>\n",
       "      <th>predicateType</th>\n",
       "      <th>group</th>\n",
       "      <th>limit</th>\n",
       "      <th>attributes</th>\n",
       "      <th>decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cps/basic/jan</td>\n",
       "      <td>2021</td>\n",
       "      <td>Current Population Survey: Basic Monthly</td>\n",
       "      <td>for</td>\n",
       "      <td>Census API FIPS 'for' clause</td>\n",
       "      <td>Census API Geography Specification</td>\n",
       "      <td>fips-for</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset_name  year                                     title  \\\n",
       "0  cps/basic/jan  2021  Current Population Survey: Basic Monthly   \n",
       "\n",
       "  variable_name                         label  \\\n",
       "0           for  Census API FIPS 'for' clause   \n",
       "\n",
       "                              concept predicateType group  limit attributes  \\\n",
       "0  Census API Geography Specification      fips-for   NaN      0        NaN   \n",
       "\n",
       "  decade  \n",
       "0  2020s  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables Metadata for UNKN Loaded:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>variable_name</th>\n",
       "      <th>label</th>\n",
       "      <th>concept</th>\n",
       "      <th>predicateType</th>\n",
       "      <th>group</th>\n",
       "      <th>limit</th>\n",
       "      <th>attributes</th>\n",
       "      <th>decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://api.census.gov/data/timeseries/asm/stat...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Time Series Annual Survey of Manufactures: Sta...</td>\n",
       "      <td>for</td>\n",
       "      <td>Census API FIPS 'for' clause</td>\n",
       "      <td>Census API Geography Specification</td>\n",
       "      <td>fips-for</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        dataset_name     year  \\\n",
       "0  http://api.census.gov/data/timeseries/asm/stat...  Unknown   \n",
       "\n",
       "                                               title variable_name  \\\n",
       "0  Time Series Annual Survey of Manufactures: Sta...           for   \n",
       "\n",
       "                          label                             concept  \\\n",
       "0  Census API FIPS 'for' clause  Census API Geography Specification   \n",
       "\n",
       "  predicateType group  limit attributes   decade  \n",
       "0      fips-for   NaN      0        NaN  Unknown  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Datasets Metadata:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>identifier</th>\n",
       "      <th>contact</th>\n",
       "      <th>access_level</th>\n",
       "      <th>modified</th>\n",
       "      <th>publisher</th>\n",
       "      <th>references</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cps</td>\n",
       "      <td>1994</td>\n",
       "      <td>Jun 1994 Current Population Survey: Basic Monthly</td>\n",
       "      <td>To provide estimates of employment, unemployme...</td>\n",
       "      <td>https://api.census.gov/data/id/CPSBASIC199406</td>\n",
       "      <td>CPS Staff</td>\n",
       "      <td>public</td>\n",
       "      <td>2019-10-09 15:05:36.0</td>\n",
       "      <td>U.S. Census Bureau</td>\n",
       "      <td>https://www.census.gov/developers/</td>\n",
       "      <td>census</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset_name  year                                              title  \\\n",
       "0          cps  1994  Jun 1994 Current Population Survey: Basic Monthly   \n",
       "\n",
       "                                         description  \\\n",
       "0  To provide estimates of employment, unemployme...   \n",
       "\n",
       "                                      identifier    contact access_level  \\\n",
       "0  https://api.census.gov/data/id/CPSBASIC199406  CPS Staff       public   \n",
       "\n",
       "                modified           publisher  \\\n",
       "0  2019-10-09 15:05:36.0  U.S. Census Bureau   \n",
       "\n",
       "                           references keywords  \n",
       "0  https://www.census.gov/developers/   census  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Variables Metadata:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>variable_name</th>\n",
       "      <th>label</th>\n",
       "      <th>concept</th>\n",
       "      <th>predicateType</th>\n",
       "      <th>group</th>\n",
       "      <th>limit</th>\n",
       "      <th>attributes</th>\n",
       "      <th>decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbp</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986 County Business Patterns: Business Patterns</td>\n",
       "      <td>for</td>\n",
       "      <td>Census API FIPS 'for' clause</td>\n",
       "      <td>Census API Geography Specification</td>\n",
       "      <td>fips-for</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset_name  year                                             title  \\\n",
       "0          cbp  1986  1986 County Business Patterns: Business Patterns   \n",
       "\n",
       "  variable_name                         label  \\\n",
       "0           for  Census API FIPS 'for' clause   \n",
       "\n",
       "                              concept predicateType group  limit attributes  \\\n",
       "0  Census API Geography Specification      fips-for   NaN      0        NaN   \n",
       "\n",
       "  decade  \n",
       "0  1980s  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data ingest completed.\n"
     ]
    }
   ],
   "source": [
    "# File paths for variables metadata (by decade)\n",
    "variables_file_paths = {\n",
    "    '1980s': \"./data/census_metadata_1980s.csv\",\n",
    "    '1990s': \"./data/census_metadata_1990s.csv\",\n",
    "    '2000s': \"./data/census_metadata_2000s.csv\",\n",
    "    '2010s': \"./data/census_metadata_2010s.csv\",\n",
    "    '2020s': \"./data/census_metadata_2020s.csv\",\n",
    "    'UNKN': \"./data/census_metadata_Unknown.csv\"\n",
    "}\n",
    "\n",
    "# Helper function for handling 'Unknown' years\n",
    "def handle_unknown_years(df):\n",
    "    \"\"\"Replaces 'Unknown' in the 'year' column with 9999 for consistency.\"\"\"\n",
    "    if 'year' in df.columns:\n",
    "        df['year'] = df['year'].astype(str)  # Ensure 'year' is treated as a string\n",
    "        df['year'] = df['year'].replace('Unknown', '9999')  # Replace 'Unknown' with 9999\n",
    "    return df\n",
    "\n",
    "# Function to load datasets metadata\n",
    "def load_datasets_metadata(file_path):\n",
    "    \"\"\"\n",
    "    Load the combined datasets metadata file.\n",
    "    Args:\n",
    "        file_path (str): Path to the datasets metadata CSV file.\n",
    "    Returns:\n",
    "        pd.DataFrame: Loaded datasets metadata.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        datasets_metadata = pd.read_csv(file_path)\n",
    "        print(\"Datasets Metadata Loaded:\")\n",
    "        display(datasets_metadata.head(1))\n",
    "        return datasets_metadata\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found: {file_path}\")\n",
    "        return pd.DataFrame()  # Return empty DataFrame if file not found\n",
    "\n",
    "# Function to load variables metadata\n",
    "def load_variables_metadata(file_paths):\n",
    "    \"\"\"\n",
    "    Load and combine variables metadata files for all decades.\n",
    "    Args:\n",
    "        file_paths (dict): Dictionary of decade to file path mappings.\n",
    "    Returns:\n",
    "        pd.DataFrame: Combined variables metadata.\n",
    "    \"\"\"\n",
    "    all_variables_metadata = []\n",
    "    for decade, file_path in file_paths.items():\n",
    "        try:\n",
    "            # Load metadata for the current decade\n",
    "            variables_metadata = pd.read_csv(file_path, low_memory=False)\n",
    "            print(f\"Variables Metadata for {decade} Loaded:\")\n",
    "            display(variables_metadata.head(1))\n",
    "\n",
    "            # Handle 'Unknown' year values for the UNKN dataset\n",
    "            if decade == 'UNKN':\n",
    "                variables_metadata = handle_unknown_years(variables_metadata)\n",
    "\n",
    "            all_variables_metadata.append(variables_metadata)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: File not found for {decade}: {file_path}\")\n",
    "            continue\n",
    "\n",
    "    # Combine all variables metadata into one dataframe\n",
    "    combined_variables_metadata = pd.concat(all_variables_metadata, ignore_index=True)\n",
    "\n",
    "    # Ensure the 'year' column is numeric and handle invalid values\n",
    "    if 'year' in combined_variables_metadata.columns:\n",
    "        combined_variables_metadata['year'] = pd.to_numeric(combined_variables_metadata['year'], errors='coerce')\n",
    "        combined_variables_metadata['year'] = combined_variables_metadata['year'].fillna(9999)  # Replace NaNs with 9999\n",
    "        combined_variables_metadata['year'] = combined_variables_metadata['year'].astype(int)  # Convert to integer type\n",
    "\n",
    "    return combined_variables_metadata\n",
    "\n",
    "# File path for the datasets metadata\n",
    "datasets_file_path = \"./data/census_datasets_metadata_cleaned.csv\"\n",
    "\n",
    "# Load both datasets and variables metadata\n",
    "datasets_metadata = load_datasets_metadata(datasets_file_path)\n",
    "combined_variables_metadata = load_variables_metadata(variables_file_paths)\n",
    "\n",
    "# Display loaded datasets and variables metadata\n",
    "print(\"Combined Datasets Metadata:\")\n",
    "display(datasets_metadata.head(1))\n",
    "\n",
    "print(\"Combined Variables Metadata:\")\n",
    "display(combined_variables_metadata.head(1))\n",
    "\n",
    "# Save the cleaned data to new CSV files (optional)\n",
    "combined_variables_metadata.to_csv('./data/combined_variables_metadata.csv', index=False)\n",
    "datasets_metadata.to_csv('./data/cleaned_datasets_metadata.csv', index=False)\n",
    "\n",
    "print(\"Data ingest completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452f4d37-1291-4db2-b29d-270c0d250baf",
   "metadata": {},
   "source": [
    "# 3. Clean the Data\n",
    "\n",
    "## **Data Structuring and Relationship Design**\n",
    "\n",
    "### **Overview**\n",
    "The goal of structuring the data is to create a hierarchical and navigable knowledge graph that balances usability and precision. This involves grouping repeated surveys into logical parent-child relationships while maintaining links to their associated variables and years.\n",
    "\n",
    "### **Key Design Decisions**\n",
    "1. **Parent-Child Relationships for Datasets:**\n",
    "   - **Why:** Many surveys are conducted multiple times per year, with variations in their metadata. A parent-child hierarchy simplifies navigation for users querying high-level information while retaining granularity for specific queries.\n",
    "   - **How:** We use the `parent_dataset` field to represent the high-level grouping (e.g., `cps` for the Current Population Survey) and `dataset_name` for specific instances (e.g., `cps/basic/jan` for the January survey).\n",
    "\n",
    "2. **Linking Variables to Child Datasets:**\n",
    "   - **Why:** Each dataset instance includes specific variables. Establishing this connection allows users to query datasets for their variables or find which datasets a variable belongs to.\n",
    "   - **How:** We create `Variable` nodes linked to `ChildDataset` nodes via an `INCLUDES` relationship.\n",
    "\n",
    "3. **Year-Based Relationships:**\n",
    "   - **Why:** Many datasets are time-specific. Linking datasets to their respective years ensures queries can filter datasets by year and handle temporal questions like, \"What data is available for 1986?\"\n",
    "   - **How:** We create `Year` nodes and connect them to `ChildDataset` nodes via a `BELONGS_TO_YEAR` relationship.\n",
    "\n",
    "### **Graph Schema**\n",
    "Here is the schema we use to represent the relationships:\n",
    "- **ParentDataset**: Represents high-level groupings of surveys (e.g., `cps`, `cbp`).\n",
    "  - **Relationships:**\n",
    "    - `PARENT_OF` → `ChildDataset`\n",
    "- **ChildDataset**: Represents individual survey instances (e.g., `cps/basic/jan`).\n",
    "  - **Relationships:**\n",
    "    - `INCLUDES` → `Variable`\n",
    "    - `BELONGS_TO_YEAR` → `Year`\n",
    "- **Variable**: Represents specific data variables (e.g., `employment_status`).\n",
    "- **Year**: Represents the temporal context for datasets (e.g., `1986`).\n",
    "\n",
    "### **Why This Structure?**\n",
    "This design ensures:\n",
    "- **Scalability**: Easily add new datasets, variables, and years.\n",
    "- **Usability**: Queries can target high-level overviews or specific details.\n",
    "- **Flexibility**: Supports both general and granular user queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ab13d31c-bed4-4936-99a1-5ede62dba6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading datasets_metadata and variables_metadata...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s1/yqb3d76d7053f7dyy9fwtkzw0000gp/T/ipykernel_97248/3101690510.py:49: DtypeWarning: Columns (7,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  variables_metadata = pd.read_csv('./data/combined_variables_metadata.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata loaded.\n",
      "Survey Nodes: 298\n",
      "Dataset Nodes: 3954\n",
      "Variable Nodes: 2693973\n",
      "Survey-to-Dataset Relationships: 3954\n",
      "Dataset-to-Variable Relationships: 2693973\n",
      "Debug files saved:\n",
      "- survey_nodes_debug.csv\n",
      "- dataset_nodes_debug.csv\n",
      "- variable_nodes_debug.csv\n",
      "- survey_to_dataset_relationships_debug.csv\n",
      "- dataset_to_variable_relationships_debug.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def restructure_for_graph(datasets_metadata, variables_metadata):\n",
    "    \"\"\"\n",
    "    Restructure datasets and variables metadata for hierarchical knowledge graph.\n",
    "    Args:\n",
    "        datasets_metadata (pd.DataFrame): Metadata for datasets.\n",
    "        variables_metadata (pd.DataFrame): Metadata for variables.\n",
    "    Returns:\n",
    "        dict: Nodes and relationships for building the graph.\n",
    "    \"\"\"\n",
    "    # Step 1: Extract unique surveys\n",
    "    surveys = datasets_metadata['dataset_name'].str.split('/').str[0].unique()\n",
    "    survey_nodes = pd.DataFrame({'survey': surveys})\n",
    "    print(f\"Survey Nodes: {survey_nodes.shape[0]}\")\n",
    "\n",
    "    # Step 2: Create dataset nodes\n",
    "    datasets_metadata['parent_survey'] = datasets_metadata['dataset_name'].str.split('/').str[0]\n",
    "    datasets_metadata['month'] = datasets_metadata['title'].str.extract(r'(\\bJan|\\bFeb|\\bMar|\\bApr|\\bMay|\\bJun|\\bJul|\\bAug|\\bSep|\\bOct|\\bNov|\\bDec)', expand=False)\n",
    "\n",
    "    dataset_nodes = datasets_metadata[['parent_survey', 'year', 'month', 'title', 'description']].drop_duplicates()\n",
    "    dataset_nodes['dataset_id'] = dataset_nodes.apply(lambda x: f\"{x['parent_survey']}_{x['year']}_{x['month'] or 'Annual'}\", axis=1)\n",
    "    print(f\"Dataset Nodes: {dataset_nodes.shape[0]}\")\n",
    "\n",
    "    # Step 3: Create variable nodes\n",
    "    variables_metadata['parent_survey'] = variables_metadata['dataset_name'].str.split('/').str[0]\n",
    "    variable_nodes = variables_metadata[['parent_survey', 'dataset_name', 'year', 'variable_name', 'label', 'concept']].drop_duplicates()\n",
    "    print(f\"Variable Nodes: {variable_nodes.shape[0]}\")\n",
    "\n",
    "    # Step 4: Create relationships\n",
    "    survey_to_dataset = dataset_nodes[['parent_survey', 'dataset_id']]\n",
    "    dataset_to_variable = variable_nodes[['dataset_name', 'variable_name']]\n",
    "    print(f\"Survey-to-Dataset Relationships: {survey_to_dataset.shape[0]}\")\n",
    "    print(f\"Dataset-to-Variable Relationships: {dataset_to_variable.shape[0]}\")\n",
    "\n",
    "    return {\n",
    "        'survey_nodes': survey_nodes,\n",
    "        'dataset_nodes': dataset_nodes,\n",
    "        'variable_nodes': variable_nodes,\n",
    "        'relationships': {\n",
    "            'survey_to_dataset': survey_to_dataset,\n",
    "            'dataset_to_variable': dataset_to_variable\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Reload and clean metadata\n",
    "print(\"Reloading datasets_metadata and variables_metadata...\")\n",
    "datasets_metadata = pd.read_csv('./data/census_datasets_metadata.csv')\n",
    "variables_metadata = pd.read_csv('./data/combined_variables_metadata.csv')\n",
    "print(\"Metadata loaded.\")\n",
    "\n",
    "# Restructure for graph\n",
    "graph_data = restructure_for_graph(datasets_metadata, variables_metadata)\n",
    "\n",
    "# Extract nodes and relationships\n",
    "survey_nodes = graph_data['survey_nodes']\n",
    "dataset_nodes = graph_data['dataset_nodes']\n",
    "variable_nodes = graph_data['variable_nodes']\n",
    "survey_to_dataset_relationships = graph_data['relationships']['survey_to_dataset']\n",
    "dataset_to_variable_relationships = graph_data['relationships']['dataset_to_variable']\n",
    "\n",
    "# Save to CSV (optional)\n",
    "survey_nodes.to_csv('./data/survey_nodes_debug.csv', index=False)\n",
    "dataset_nodes.to_csv('./data/dataset_nodes_debug.csv', index=False)\n",
    "variable_nodes.to_csv('./data/variable_nodes_debug.csv', index=False)\n",
    "survey_to_dataset_relationships.to_csv('./data/survey_to_dataset_relationships_debug.csv', index=False)\n",
    "dataset_to_variable_relationships.to_csv('./data/dataset_to_variable_relationships_debug.csv', index=False)\n",
    "\n",
    "print(\"Debug files saved:\")\n",
    "print(\"- survey_nodes_debug.csv\")\n",
    "print(\"- dataset_nodes_debug.csv\")\n",
    "print(\"- variable_nodes_debug.csv\")\n",
    "print(\"- survey_to_dataset_relationships_debug.csv\")\n",
    "print(\"- dataset_to_variable_relationships_debug.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d6d11243-f185-4e50-851c-7e77101cc5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Surveys:\n",
      "cps\n",
      "basic\n",
      "jun\n",
      "cbp\n",
      "zbp\n",
      "mar\n",
      "apr\n",
      "pep\n",
      "int_charagegroups\n",
      "aug\n",
      "int_natcivpop\n",
      "int_natresafo\n",
      "dec\n",
      "int_natrespop\n",
      "may\n",
      "ewks\n",
      "jan\n",
      "jul\n",
      "feb\n",
      "nov\n",
      "oct\n",
      "sep\n",
      "nonemp\n",
      "int_charage\n",
      "int_housingunits\n",
      "int_natmonthly\n",
      "int_population\n",
      "surname\n",
      "acs\n",
      "acs1\n",
      "cprofile\n",
      "pums\n",
      "acs5\n",
      "plnat\n",
      "profile\n",
      "subject\n",
      "flows\n",
      "cd113\n",
      "cd115\n",
      "sf1\n",
      "sf2\n",
      "ecnbridge2\n",
      "ecnadmben\n",
      "ecnbranddeal\n",
      "ecnbridge1\n",
      "ecncashadv\n",
      "ecnbrordeal\n",
      "ecnccard\n",
      "ecninvval\n",
      "ecnclcust\n",
      "ecnipa\n",
      "ecncomm\n",
      "ecnkob\n",
      "ecncomp\n",
      "ecnlabor\n",
      "ecnfran\n",
      "ecnconact\n",
      "ecnconcess\n",
      "ecnlifomfg\n",
      "ecncrfin\n",
      "ecnlifomine\n",
      "ecngrant\n",
      "ecndissmed\n",
      "ecnempfunc\n",
      "ecnlifoval\n",
      "ecnentsup\n",
      "ecnlines\n",
      "ecnguest\n",
      "ecneoyinv\n",
      "ecneoyinvwh\n",
      "ecnloan\n",
      "ecnequip\n",
      "ecnlocmfg\n",
      "ecnguestsize\n",
      "ecnexpnrg\n",
      "ecnexpsvc\n",
      "ecnlocmine\n",
      "ecnflspace\n",
      "ecnmargin\n",
      "ecnfoodsvc\n",
      "ecnhosp\n",
      "ecnmatfuel\n",
      "ecnmealcost\n",
      "ecnmenutype\n",
      "ecnpatient\n",
      "ecnpetrfac\n",
      "ecnpetrprod\n",
      "ecnpetrrec\n",
      "ecnpetrstat\n",
      "ecnprofit\n",
      "ecnpurelec\n",
      "ecnpurmode\n",
      "ecnrdacq\n",
      "ecnrdofc\n",
      "ecnseat\n",
      "ecnsize\n",
      "ecnsocial\n",
      "ecntype\n",
      "ecntypop\n",
      "ecnvalcon\n",
      "sbo\n",
      "cscbo\n",
      "popproj\n",
      "births\n",
      "deaths\n",
      "nim\n",
      "pop\n",
      "pubschlfin\n",
      "cre\n",
      "cscb\n",
      "language\n",
      "cochar5\n",
      "cochar6\n",
      "cty\n",
      "housing\n",
      "monthlynatchar5\n",
      "monthlynatchar6\n",
      "natstprc18\n",
      "natstprc\n",
      "prcagesex\n",
      "prm\n",
      "prmagesex\n",
      "stchar5\n",
      "stchar6\n",
      "subcty\n",
      "acsse\n",
      "ase\n",
      "csa\n",
      "asec\n",
      "agesex\n",
      "intltrade\n",
      "imp_exp\n",
      "agespecial5\n",
      "agespecial6\n",
      "agespecialpr\n",
      "projnim\n",
      "projagegroups\n",
      "projpop\n",
      "projbirths\n",
      "projdeaths\n",
      "projnat\n",
      "pdb\n",
      "blockgroup\n",
      "tract\n",
      "charage\n",
      "charagegroups\n",
      "components\n",
      "natmonthly\n",
      "population\n",
      "spp\n",
      "cfsarea\n",
      "cd116\n",
      "ecnbasic\n",
      "pumspr\n",
      "cfsexport\n",
      "cfshazmat\n",
      "cfsprelim\n",
      "ecn\n",
      "islandareas\n",
      "acs3\n",
      "comp\n",
      "napcs\n",
      "agegroups\n",
      "nat\n",
      "responserate\n",
      "pl\n",
      "aian\n",
      "ind\n",
      "lines\n",
      "statecounty\n",
      "disability\n",
      "abscb\n",
      "abscbo\n",
      "abscs\n",
      "tobacco\n",
      "asyoe\n",
      "guyoe\n",
      "mpyoe\n",
      "as\n",
      "mp\n",
      "vi\n",
      "sptprofile\n",
      "gu\n",
      "cfstemp\n",
      "school\n",
      "foodsec\n",
      "aianprofile\n",
      "spt\n",
      "internet\n",
      "vets\n",
      "cd110h\n",
      "volunteer\n",
      "dwjt\n",
      "unbank\n",
      "cd110hprofile\n",
      "sf3profile\n",
      "sldhprofile\n",
      "sldsprofile\n",
      "cd113profile\n",
      "sf2profile\n",
      "ecnnapcsind\n",
      "ecnnapcsprd\n",
      "sf3\n",
      "cd115profile\n",
      "sf4profile\n",
      "sf4\n",
      "sldh\n",
      "slds\n",
      "ecnloccons\n",
      "cd110s\n",
      "arts\n",
      "abstcb\n",
      "cd110sprofile\n",
      "cqr\n",
      "ecnpurgas\n",
      "voting\n",
      "ecninstr\n",
      "fertility\n",
      "ecndirprem\n",
      "ecnadbnprop\n",
      "ecnelmenu\n",
      "ecnhotel\n",
      "ecntypepayer\n",
      "marital\n",
      "immigration\n",
      "cs\n",
      "pubarts\n",
      "absnesd\n",
      "absnesdo\n",
      "eeo\n",
      "pes\n",
      "civic\n",
      "dpas\n",
      "dpgu\n",
      "dpmp\n",
      "dpvi\n",
      "absmcb\n",
      "contworker\n",
      "race\n",
      "library\n",
      "worksched\n",
      "dhc\n",
      "dp\n",
      "dhcas\n",
      "dhcgu\n",
      "dhcmp\n",
      "dhcvi\n",
      "cd118\n",
      "ddhca\n",
      "viusa\n",
      "viusb\n",
      "viusc\n",
      "viusd\n",
      "viuse\n",
      "viusf\n",
      "sipp\n",
      "core\n",
      "2008panel\n",
      "wave14\n",
      "wave10\n",
      "wave16\n",
      "wave1\n",
      "wave11\n",
      "wave15\n",
      "wave12\n",
      "wave2\n",
      "wave13\n",
      "wave3\n",
      "wave4\n",
      "wave5\n",
      "wave6\n",
      "wave7\n",
      "wave8\n",
      "wave9\n",
      "topical\n",
      "2004panel\n",
      "2001panel\n",
      "topicalres\n",
      "crosstabas\n",
      "crosstabgu\n",
      "crosstabmp\n",
      "crosstabvi\n",
      "1996panel\n",
      "1993panel\n",
      "topicaled\n",
      "topicaledex\n",
      "topicalex\n",
      "1992panel\n",
      "1990panel\n",
      "benefit\n",
      "1991panel\n",
      "viuspuf\n",
      "crepuertorico\n",
      "selfresponserate\n",
      "ddhcb\n",
      "rhfs\n",
      "geoinfo\n",
      "sdhc\n",
      "\n",
      "Survey Counts:\n",
      "dataset_name\n",
      "cps             667\n",
      "basic           428\n",
      "acs             246\n",
      "sipp            176\n",
      "dec             122\n",
      "               ... \n",
      "sf4profile        1\n",
      "cd115profile      1\n",
      "sf3               1\n",
      "ecnnapcsprd       1\n",
      "sdhc              1\n",
      "Name: count, Length: 298, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Unique top-level survey names\n",
    "unique_surveys = datasets_metadata['dataset_name'].str.split('/').str[0].unique()\n",
    "print(\"Unique Surveys:\")\n",
    "for survey in unique_surveys:\n",
    "    print(survey)\n",
    "\n",
    "# Count occurrences of each survey\n",
    "survey_counts = datasets_metadata['dataset_name'].str.split('/').str[0].value_counts()\n",
    "print(\"\\nSurvey Counts:\")\n",
    "print(survey_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773504dc-3553-4809-82c3-086c0daade1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cd48ad5b-af68-4a40-8bb1-e18ae4f71119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Remaining Surveys After Filtering:\n",
      "['cps' 'cbp' 'zbp' 'pep' 'int_charagegroups' 'int_natcivpop'\n",
      " 'int_natresafo' 'int_natrespop' 'ewks' 'nonemp' 'int_charage'\n",
      " 'int_housingunits' 'int_natmonthly' 'int_population' 'surname' 'acs'\n",
      " 'acs1' 'cprofile' 'pums' 'acs5' 'plnat' 'profile' 'subject' 'flows'\n",
      " 'cd113' 'cd115' 'sf1' 'sf2' 'ecnbridge2' 'ecnadmben' 'ecnbranddeal'\n",
      " 'ecnbridge1' 'ecncashadv' 'ecnbrordeal' 'ecnccard' 'ecninvval'\n",
      " 'ecnclcust' 'ecnipa' 'ecncomm' 'ecnkob' 'ecncomp' 'ecnlabor' 'ecnfran'\n",
      " 'ecnconact' 'ecnconcess' 'ecnlifomfg' 'ecncrfin' 'ecnlifomine' 'ecngrant'\n",
      " 'ecndissmed' 'ecnempfunc' 'ecnlifoval' 'ecnentsup' 'ecnlines' 'ecnguest'\n",
      " 'ecneoyinv' 'ecneoyinvwh' 'ecnloan' 'ecnequip' 'ecnlocmfg' 'ecnguestsize'\n",
      " 'ecnexpnrg' 'ecnexpsvc' 'ecnlocmine' 'ecnflspace' 'ecnmargin'\n",
      " 'ecnfoodsvc' 'ecnhosp' 'ecnmatfuel' 'ecnmealcost' 'ecnmenutype'\n",
      " 'ecnpatient' 'ecnpetrfac' 'ecnpetrprod' 'ecnpetrrec' 'ecnpetrstat'\n",
      " 'ecnprofit' 'ecnpurelec' 'ecnpurmode' 'ecnrdacq' 'ecnrdofc' 'ecnseat'\n",
      " 'ecnsize' 'ecnsocial' 'ecntype' 'ecntypop' 'ecnvalcon' 'sbo' 'cscbo'\n",
      " 'popproj' 'births' 'deaths' 'nim' 'pop' 'pubschlfin' 'cre' 'cscb'\n",
      " 'language' 'cochar5' 'cochar6' 'cty' 'housing' 'monthlynatchar5'\n",
      " 'monthlynatchar6' 'natstprc18' 'natstprc' 'prcagesex' 'prm' 'prmagesex'\n",
      " 'stchar5' 'stchar6' 'subcty' 'acsse' 'ase' 'csa' 'asec' 'agesex'\n",
      " 'intltrade' 'imp_exp' 'agespecial5' 'agespecial6' 'agespecialpr'\n",
      " 'projnim' 'projagegroups' 'projpop' 'projbirths' 'projdeaths' 'projnat'\n",
      " 'pdb' 'blockgroup' 'tract' 'charage' 'charagegroups' 'components'\n",
      " 'natmonthly' 'population' 'spp' 'cfsarea' 'cd116' 'ecnbasic' 'pumspr'\n",
      " 'cfsexport' 'cfshazmat' 'cfsprelim' 'ecn' 'islandareas' 'acs3' 'comp'\n",
      " 'napcs' 'agegroups' 'nat' 'responserate' 'pl' 'aian' 'ind' 'lines'\n",
      " 'statecounty' 'disability' 'abscb' 'abscbo' 'abscs' 'tobacco' 'asyoe'\n",
      " 'guyoe' 'mpyoe' 'as' 'mp' 'vi' 'sptprofile' 'gu' 'cfstemp' 'school'\n",
      " 'foodsec' 'aianprofile' 'spt' 'internet' 'vets' 'cd110h' 'volunteer'\n",
      " 'dwjt' 'unbank' 'cd110hprofile' 'sf3profile' 'sldhprofile' 'sldsprofile'\n",
      " 'cd113profile' 'sf2profile' 'ecnnapcsind' 'ecnnapcsprd' 'sf3'\n",
      " 'cd115profile' 'sf4profile' 'sf4' 'sldh' 'slds' 'ecnloccons' 'cd110s'\n",
      " 'arts' 'abstcb' 'cd110sprofile' 'cqr' 'ecnpurgas' 'voting' 'ecninstr'\n",
      " 'fertility' 'ecndirprem' 'ecnadbnprop' 'ecnelmenu' 'ecnhotel'\n",
      " 'ecntypepayer' 'marital' 'immigration' 'cs' 'pubarts' 'absnesd'\n",
      " 'absnesdo' 'eeo' 'pes' 'civic' 'dpas' 'dpgu' 'dpmp' 'dpvi' 'absmcb'\n",
      " 'contworker' 'race' 'library' 'worksched' 'dhc' 'dp' 'dhcas' 'dhcgu'\n",
      " 'dhcmp' 'dhcvi' 'cd118' 'ddhca' 'viusa' 'viusb' 'viusc' 'viusd' 'viuse'\n",
      " 'viusf' 'sipp' 'core' '2008panel' 'wave14' 'wave10' 'wave16' 'wave1'\n",
      " 'wave11' 'wave15' 'wave12' 'wave2' 'wave13' 'wave3' 'wave4' 'wave5'\n",
      " 'wave6' 'wave7' 'wave8' 'wave9' 'topical' '2004panel' '2001panel'\n",
      " 'topicalres' 'crosstabas' 'crosstabgu' 'crosstabmp' 'crosstabvi'\n",
      " '1996panel' '1993panel' 'topicaled' 'topicaledex' 'topicalex' '1992panel'\n",
      " '1990panel' 'benefit' '1991panel' 'viuspuf' 'crepuertorico'\n",
      " 'selfresponserate' 'ddhcb' 'rhfs' 'geoinfo' 'sdhc']\n",
      "\n",
      "Filtered datasets saved to './data/cleaned_datasets_metadata.csv'\n"
     ]
    }
   ],
   "source": [
    "# Define surveys to remove\n",
    "surveys_to_remove = [\n",
    "    'basic', 'jan', 'feb', 'mar', 'apr', 'may', \n",
    "    'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec'\n",
    "]\n",
    "\n",
    "# Filter out the redundant entries\n",
    "datasets_metadata = datasets_metadata[\n",
    "    ~datasets_metadata['dataset_name'].str.split('/').str[0].isin(surveys_to_remove)\n",
    "]\n",
    "\n",
    "# Recheck the unique surveys after removal\n",
    "remaining_surveys = datasets_metadata['dataset_name'].str.split('/').str[0].unique()\n",
    "print(\"\\nRemaining Surveys After Filtering:\")\n",
    "print(remaining_surveys)\n",
    "\n",
    "# Save the cleaned dataset for further inspection\n",
    "datasets_metadata.to_csv('./data/cleaned_datasets_metadata.csv', index=False)\n",
    "print(\"\\nFiltered datasets saved to './data/cleaned_datasets_metadata.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c2e78ee3-abdd-4007-bf9c-8d725170e423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered Datasets Metadata:\n",
      "  dataset_name  year                                              title  \\\n",
      "0          cps  1994  Jun 1994 Current Population Survey: Basic Monthly   \n",
      "3          cbp  1986   1986 County Business Patterns: Business Patterns   \n",
      "4          zbp  1994  1994 County Business Patterns - Zip Code Busin...   \n",
      "5          cbp  1987   1987 County Business Patterns: Business Patterns   \n",
      "6          cbp  1995   1995 County Business Patterns: Business Patterns   \n",
      "\n",
      "                                         description  \\\n",
      "0  To provide estimates of employment, unemployme...   \n",
      "3  County Business Patterns (CBP) is an annual se...   \n",
      "4  ZIP Code Business Patterns (ZBP) is an annual ...   \n",
      "5  County Business Patterns (CBP) is an annual se...   \n",
      "6  County Business Patterns (CBP) is an annual se...   \n",
      "\n",
      "                                      identifier    contact access_level  \\\n",
      "0  https://api.census.gov/data/id/CPSBASIC199406  CPS Staff       public   \n",
      "3          http://api.census.gov/data/id/CBP1986  CBP Staff       public   \n",
      "4     http://api.census.gov/data/id/ZBPTotal1994  CBP Staff       public   \n",
      "5          http://api.census.gov/data/id/CBP1987  CBP Staff       public   \n",
      "6          http://api.census.gov/data/id/CBP1995  CBP Staff       public   \n",
      "\n",
      "                modified           publisher  \\\n",
      "0  2019-10-09 15:05:36.0  U.S. Census Bureau   \n",
      "3             2019-02-13  U.S. Census Bureau   \n",
      "4             2018-01-25  U.S. Census Bureau   \n",
      "5             2019-02-13  U.S. Census Bureau   \n",
      "6             2019-02-13  U.S. Census Bureau   \n",
      "\n",
      "                           references keywords parent_survey month  \n",
      "0  https://www.census.gov/developers/   census           cps   Jun  \n",
      "3   http://www.census.gov/developers/   census           cbp   NaN  \n",
      "4   http://www.census.gov/developers/   census           zbp   NaN  \n",
      "5   http://www.census.gov/developers/   census           cbp   NaN  \n",
      "6   http://www.census.gov/developers/   census           cbp   NaN  \n",
      "\n",
      "Filtered datasets saved to './data/cleaned_datasets_metadata.csv'\n"
     ]
    }
   ],
   "source": [
    "# Ensure `parent_survey` column exists in the datasets_metadata\n",
    "datasets_metadata['parent_survey'] = datasets_metadata['dataset_name'].str.split('/').str[0]\n",
    "\n",
    "# Filter rows where parent_survey equals dataset_name\n",
    "datasets_metadata = datasets_metadata[datasets_metadata['parent_survey'] == datasets_metadata['dataset_name']]\n",
    "\n",
    "# Check the resulting DataFrame\n",
    "print(\"\\nFiltered Datasets Metadata:\")\n",
    "print(datasets_metadata.head())\n",
    "\n",
    "# Save the filtered dataset to a new file for further inspection\n",
    "datasets_metadata.to_csv('./data/cleaned_datasets_metadata.csv', index=False)\n",
    "print(\"\\nFiltered datasets saved to './data/cleaned_datasets_metadata.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7492698-2d15-4e3b-9556-5423253d913b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a782641-326e-4c08-b568-814dbc108408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38a26fd-20ef-460c-a6fa-8eeb0920be7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7497dc-b41c-47a8-80f0-37b0115c89be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9574e7-382b-4253-b966-191df3071f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f56e4ec-00c3-4d3f-b88a-36ae609d9b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78d5c5b9-4308-47c9-820f-6fc24d120a8f",
   "metadata": {},
   "source": [
    "# 4. Connect to Neo4j\n",
    "- This cell sets up the Neo4j connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0c613301-40ee-4d0c-a216-a8c9e9e6f377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful.\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Initialize Neo4j connection (replace with your credentials)\n",
    "neo4j_uri = \"bolt://localhost:7687\"  # Update with your Neo4j URI\n",
    "neo4j_user = \"neo4j\"\n",
    "neo4j_password = \"password\"  # Update with your password\n",
    "\n",
    "try:\n",
    "    # Create a driver instance\n",
    "    driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))\n",
    "    \n",
    "    # Test connection by opening a session and executing a simple query\n",
    "    with driver.session() as session:\n",
    "        session.run(\"RETURN 1\")  # Simple query to check connection\n",
    "    print(\"Connection successful.\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06216e2c-9b7a-4908-8bdd-080576506912",
   "metadata": {},
   "source": [
    "# 5. Ingest Data into Neo4j\n",
    "- This cell contains the ingestion logic.\n",
    "\n",
    "## Clear the Neo4J dB if necessary\n",
    "To delete all the data in your Neo4j database, you can use the following Cypher query, which will remove all nodes and relationships: \\\n",
    "> MATCH (n) \\\n",
    "> DETACH DELETE n\n",
    "\n",
    "### Explanation:\n",
    "- MATCH (n): This matches all nodes in the graph.\n",
    "- DETACH DELETE n: This deletes the nodes and any relationships attached to them.\n",
    "\n",
    "### How to Run:\n",
    "1. Open your Neo4j browser or a Neo4j client.\n",
    "1. Paste the query and execute it.\n",
    "\n",
    "This will completely clear your Neo4j database of all nodes and relationships, giving you a fresh starting point for your new data ingestion.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2d3d45ac-964e-4560-a4db-010207c6896b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating DataFrames...\n",
      "DataFrames created. Starting Neo4j loading process...\n",
      "Clearing existing data...\n",
      "Existing data cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Survey Nodes: 100%|██████████████████| 298/298 [00:02<00:00, 109.76it/s]\n",
      "Loading Dataset Nodes: 100%|████████████████| 3954/3954 [00:42<00:00, 94.01it/s]\n",
      "Loading Variable Nodes:   0%|         | 7000/2693973 [01:03<6:44:00, 110.85it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 70\u001b[0m\n\u001b[1;32m     59\u001b[0m load_nodes_in_batches(\n\u001b[1;32m     60\u001b[0m     driver,\n\u001b[1;32m     61\u001b[0m     dataset_nodes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading Dataset Nodes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m )\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Load Variable nodes\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m \u001b[43mload_nodes_in_batches\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariable_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;250;43m    \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"\u001b[39;49;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;43;03m    MERGE (v:Variable {variable_name: $variable_name})\u001b[39;49;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;43;03m    SET v.label = $label, v.concept = $concept\u001b[39;49;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;43;03m    \"\"\"\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLoading Variable Nodes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     78\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Create Survey -> Dataset relationships\u001b[39;00m\n\u001b[1;32m     81\u001b[0m load_relationships_in_batches(\n\u001b[1;32m     82\u001b[0m     driver,\n\u001b[1;32m     83\u001b[0m     survey_to_dataset_relationships,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating Survey -> Dataset Relationships\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     90\u001b[0m )\n",
      "Cell \u001b[0;32mIn[68], line 28\u001b[0m, in \u001b[0;36mload_nodes_in_batches\u001b[0;34m(driver, df, query, desc, batch_size)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m driver\u001b[38;5;241m.\u001b[39msession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 28\u001b[0m         \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(batch))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/graphrag_env/lib/python3.11/site-packages/neo4j/_sync/work/session.py:303\u001b[0m, in \u001b[0;36mSession.run\u001b[0;34m(self, query, parameters, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ClientError(\n\u001b[1;32m    298\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExplicit Transaction must be handled explicitly\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    299\u001b[0m     )\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_auto_result:\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;66;03m# This will buffer upp all records for the previous auto-commit tx\u001b[39;00m\n\u001b[0;32m--> 303\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_auto_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mdefault_access_mode)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/graphrag_env/lib/python3.11/site-packages/neo4j/_sync/work/result.py:454\u001b[0m, in \u001b[0;36mResult._buffer_all\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_buffer_all\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 454\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/graphrag_env/lib/python3.11/site-packages/neo4j/_sync/work/result.py:443\u001b[0m, in \u001b[0;36mResult._buffer\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    442\u001b[0m record_buffer \u001b[38;5;241m=\u001b[39m deque()\n\u001b[0;32m--> 443\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrecord_buffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrecord_buffer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/graphrag_env/lib/python3.11/site-packages/neo4j/_sync/work/result.py:393\u001b[0m, in \u001b[0;36mResult.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_record_buffer\u001b[38;5;241m.\u001b[39mpopleft()\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_streaming:\n\u001b[0;32m--> 393\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_discarding:\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_discard()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/graphrag_env/lib/python3.11/site-packages/neo4j/_sync/io/_common.py:181\u001b[0m, in \u001b[0;36mConnectionErrorHandler.__getattr__.<locals>.outer.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 181\u001b[0m         \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (Neo4jError, ServiceUnavailable, SessionExpired) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39miscoroutinefunction(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__on_error)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/graphrag_env/lib/python3.11/site-packages/neo4j/_sync/io/_bolt.py:974\u001b[0m, in \u001b[0;36mBolt.fetch_message\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# Receive exactly one message\u001b[39;00m\n\u001b[0;32m--> 974\u001b[0m tag, fields \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minbox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhydration_hooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponses\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhydration_hooks\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_message(tag, fields)\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midle_since \u001b[38;5;241m=\u001b[39m monotonic()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/graphrag_env/lib/python3.11/site-packages/neo4j/_sync/io/_common.py:74\u001b[0m, in \u001b[0;36mInbox.pop\u001b[0;34m(self, hydration_hooks)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpop\u001b[39m(\u001b[38;5;28mself\u001b[39m, hydration_hooks):\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer_one_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         size, tag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unpacker\u001b[38;5;241m.\u001b[39munpack_structure_header()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/graphrag_env/lib/python3.11/site-packages/neo4j/_sync/io/_common.py:51\u001b[0m, in \u001b[0;36mInbox._buffer_one_chunk\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m chunk_size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;66;03m# Determine the chunk size and skip noop\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m         \u001b[43mreceive_into_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_socket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m         chunk_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer\u001b[38;5;241m.\u001b[39mpop_u16()\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m chunk_size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/graphrag_env/lib/python3.11/site-packages/neo4j/_sync/io/_common.py:336\u001b[0m, in \u001b[0;36mreceive_into_buffer\u001b[0;34m(sock, buffer, n_bytes)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(buffer\u001b[38;5;241m.\u001b[39mdata) \u001b[38;5;28;01mas\u001b[39;00m view:\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m buffer\u001b[38;5;241m.\u001b[39mused \u001b[38;5;241m<\u001b[39m end:\n\u001b[0;32m--> 336\u001b[0m         n \u001b[38;5;241m=\u001b[39m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m            \u001b[49m\u001b[43mview\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mused\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mused\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    340\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/graphrag_env/lib/python3.11/site-packages/neo4j/_async_compat/network/_bolt_socket.py:521\u001b[0m, in \u001b[0;36mBoltSocket.recv_into\u001b[0;34m(self, buffer, nbytes)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecv_into\u001b[39m(\u001b[38;5;28mself\u001b[39m, buffer, nbytes):\n\u001b[0;32m--> 521\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_io\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/graphrag_env/lib/python3.11/site-packages/neo4j/_async_compat/network/_bolt_socket.py:496\u001b[0m, in \u001b[0;36mBoltSocket._wait_for_io\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wait_for_io\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deadline \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 496\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_socket\u001b[38;5;241m.\u001b[39mgettimeout()\n\u001b[1;32m    498\u001b[0m     deadline_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deadline\u001b[38;5;241m.\u001b[39mto_timeout()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize Neo4j connection\n",
    "neo4j_uri = \"bolt://localhost:7687\"\n",
    "neo4j_user = \"neo4j\"\n",
    "neo4j_password = \"password\"\n",
    "driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))\n",
    "\n",
    "# Load data from CSV files\n",
    "print(\"Creating DataFrames...\")\n",
    "survey_nodes = pd.read_csv('./data/survey_nodes.csv')\n",
    "dataset_nodes = pd.read_csv('./data/dataset_nodes.csv')\n",
    "variable_nodes = pd.read_csv('./data/variable_nodes.csv')\n",
    "survey_to_dataset_relationships = pd.read_csv('./data/survey_to_dataset_relationships.csv')\n",
    "dataset_to_variable_relationships = pd.read_csv('./data/dataset_to_variable_relationships.csv')\n",
    "print(\"DataFrames created. Starting Neo4j loading process...\")\n",
    "\n",
    "# Function to load nodes in batches with progress bar\n",
    "def load_nodes_in_batches(driver, df, query, desc, batch_size=1000):\n",
    "    total_batches = (len(df) + batch_size - 1) // batch_size\n",
    "    with tqdm(total=len(df), desc=desc) as pbar:\n",
    "        for i in range(0, len(df), batch_size):\n",
    "            batch = df.iloc[i:i + batch_size]\n",
    "            with driver.session() as session:\n",
    "                for _, row in batch.iterrows():\n",
    "                    session.run(query, **row.to_dict())\n",
    "            pbar.update(len(batch))\n",
    "\n",
    "# Function to load relationships in batches with progress bar\n",
    "def load_relationships_in_batches(driver, df, query, desc, batch_size=1000):\n",
    "    total_batches = (len(df) + batch_size - 1) // batch_size\n",
    "    with tqdm(total=len(df), desc=desc) as pbar:\n",
    "        for i in range(0, len(df), batch_size):\n",
    "            batch = df.iloc[i:i + batch_size]\n",
    "            with driver.session() as session:\n",
    "                for _, row in batch.iterrows():\n",
    "                    session.run(query, **row.to_dict())\n",
    "            pbar.update(len(batch))\n",
    "\n",
    "# Clear existing data\n",
    "with driver.session() as session:\n",
    "    print(\"Clearing existing data...\")\n",
    "    session.run(\"MATCH (n) DETACH DELETE n\")\n",
    "print(\"Existing data cleared.\")\n",
    "\n",
    "# Load Survey nodes\n",
    "load_nodes_in_batches(\n",
    "    driver,\n",
    "    survey_nodes,\n",
    "    \"\"\"\n",
    "    MERGE (s:Survey {survey: $survey})\n",
    "    \"\"\",\n",
    "    \"Loading Survey Nodes\"\n",
    ")\n",
    "\n",
    "# Load Dataset nodes\n",
    "load_nodes_in_batches(\n",
    "    driver,\n",
    "    dataset_nodes,\n",
    "    \"\"\"\n",
    "    MERGE (d:Dataset {dataset_id: $dataset_id})\n",
    "    SET d.year = $year, d.month = $month, d.title = $title, d.description = $description\n",
    "    \"\"\",\n",
    "    \"Loading Dataset Nodes\"\n",
    ")\n",
    "\n",
    "# Load Variable nodes\n",
    "load_nodes_in_batches(\n",
    "    driver,\n",
    "    variable_nodes,\n",
    "    \"\"\"\n",
    "    MERGE (v:Variable {variable_name: $variable_name})\n",
    "    SET v.label = $label, v.concept = $concept\n",
    "    \"\"\",\n",
    "    \"Loading Variable Nodes\"\n",
    ")\n",
    "\n",
    "# Create Survey -> Dataset relationships\n",
    "load_relationships_in_batches(\n",
    "    driver,\n",
    "    survey_to_dataset_relationships,\n",
    "    \"\"\"\n",
    "    MATCH (s:Survey {survey: $parent_survey})\n",
    "    MATCH (d:Dataset {dataset_id: $dataset_id})\n",
    "    MERGE (s)-[:HAS_DATASET]->(d)\n",
    "    \"\"\",\n",
    "    \"Creating Survey -> Dataset Relationships\"\n",
    ")\n",
    "\n",
    "# Create Dataset -> Variable relationships\n",
    "load_relationships_in_batches(\n",
    "    driver,\n",
    "    dataset_to_variable_relationships,\n",
    "    \"\"\"\n",
    "    MATCH (d:Dataset {dataset_id: $dataset_name})\n",
    "    MATCH (v:Variable {variable_name: $variable_name})\n",
    "    MERGE (d)-[:HAS_VARIABLE]->(v)\n",
    "    \"\"\",\n",
    "    \"Creating Dataset -> Variable Relationships\"\n",
    ")\n",
    "\n",
    "print(\"All data loaded into Neo4j successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1281dcde-c1cf-4aa1-bf5b-b4abdb70dc28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c0f27d-b487-4fe2-a16c-e4ef0b8f8819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39057c8a-2183-4960-a008-56515d3d45bf",
   "metadata": {},
   "source": [
    "# Step 6: Securely Loading OpenAI API Key and Using LLM for Concept Extraction\n",
    "\n",
    "The goal of this step is to securely load the OpenAI API key from a `.env` file and utilize the LLM (Large Language Model) to enhance the knowledge graph. By extracting key concepts and terms from variable descriptions, we enrich the graph with semantic information.\n",
    "\n",
    "**Key Steps:**\n",
    "1. **Loading the API Key**: \n",
    "    - We load the OpenAI API key securely from a `.env` file using the `python-dotenv` package. This avoids hardcoding sensitive credentials in the source code, ensuring better security and flexibility.\n",
    "   \n",
    "2. **Using LLM for Concept Extraction**:\n",
    "    - Once the API key is loaded, we use OpenAI’s GPT-based model to process the variable descriptions. The model extracts key concepts, terms, and entities from the descriptions (e.g., \"income,\" \"education level\"), which we can then use to create new concept nodes in the knowledge graph.\n",
    "   \n",
    "3. **Enhancing the Knowledge Graph**:\n",
    "    - After extracting the concepts, we create **concept nodes** and link them to the relevant **variables** using `:MEASURES` relationships. We can also link surveys that cover similar concepts, allowing us to analyze relationships between datasets based on the concepts they measure.\n",
    "\n",
    "This approach leverages the power of GPT to enhance the graph beyond simple variable names, creating a richer, more semantically aware dataset that will be useful for querying, analysis, and discovering relationships that were not obvious at first glance.\n",
    "\n",
    "## 6.1 Loading the API Key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab6e1e4-02f9-45fb-9bc0-b6ff6333dd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the OpenAI API key from the environment\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ba57a1-4b0c-40a9-a42a-d7012df8b90c",
   "metadata": {},
   "source": [
    "## 6.2 Testing functionality/connectivity of the GPT\n",
    "\n",
    "### Extracting Key Concepts with ChatGPT\n",
    "This is for testing, to be sure things are working. In this step, we'll define a function that uses OpenAI's GPT model to process variable descriptions and extract important concepts, keywords, or themes. The extracted concepts will help us create concept nodes in the knowledge graph.\n",
    "\n",
    "### Here’s the process:\n",
    "1. Input: We'll pass the variable descriptions to the GPT model via the OpenAI API.\n",
    "1. Output: The model will return key concepts or keywords that are semantically related to the descriptions.\n",
    "1. Linking: These concepts will be used to enrich the knowledge graph, creating concept nodes and linking them to the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca508a3-ef1b-4fa6-991e-11d8e5149596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def extract_concepts_from_description(description):\n",
    "    \"\"\"\n",
    "    Extract key concepts from a description using OpenAI's API\n",
    "    \n",
    "    Args:\n",
    "        description (str): The text description to analyze\n",
    "    \n",
    "    Returns:\n",
    "        str: Extracted concepts and terms\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = openai.OpenAI()  # Uses OPENAI_API_KEY from environment\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",  # Can upgrade to gpt-4 if available\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant specializing in concept extraction.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Extract key concepts and terms from this variable description: {description}\"}\n",
    "            ],\n",
    "            max_tokens=100,\n",
    "            temperature=0.5\n",
    "        )\n",
    "        \n",
    "        # Extract concepts from the response\n",
    "        concepts = response.choices[0].message.content.strip()\n",
    "        \n",
    "        return concepts\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in concept extraction: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    sample_description = \"Flag for Production workers average for year\"\n",
    "    concepts = extract_concepts_from_description(sample_description)\n",
    "    print(\"Extracted Concepts:\", concepts)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40085ad-4456-451e-9934-d6a80bfad5dc",
   "metadata": {},
   "source": [
    "## Step 6.3: Link Variables to Concepts\n",
    "\n",
    "The goal here is to take the concepts extracted from the variable descriptions and link them to their corresponding variables in the Neo4j knowledge graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ff23af-36d8-4ea8-b8c3-397e6aab6af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# Configure logging\n",
    "log_file_path = 'concept_extraction.log'\n",
    "# Ensure the log file is cleared each time\n",
    "if os.path.exists(log_file_path):\n",
    "    os.remove(log_file_path)\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=log_file_path,\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s: %(message)s'\n",
    ")\n",
    "\n",
    "# Function to extract concepts from the variable description using OpenAI\n",
    "def extract_concepts_from_description(description):\n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            model=\"gpt-3.5-turbo\",  # You can upgrade to gpt-4 if desired\n",
    "            prompt=f\"Extract key concepts and terms from this variable description: {description}\",\n",
    "            max_tokens=100,  # Limit tokens to get a concise response\n",
    "            n=1,\n",
    "            stop=None,\n",
    "            temperature=0.3\n",
    "        )\n",
    "        concepts = response.choices[0].text.strip()\n",
    "        return concepts\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in concept extraction for description '{description}': {e}\")\n",
    "        return None\n",
    "\n",
    "# Main extraction process\n",
    "def extract_missing_concepts(child_to_variable):\n",
    "    logging.info(\"Starting concept extraction for missing entries\")\n",
    "    \n",
    "    for index, row in child_to_variable.iterrows():\n",
    "        if pd.isna(row['concept']) or row['concept'] == '':  # If concept is missing\n",
    "            logging.info(f\"Attempting to extract concept for variable {row['variable_name']}\")\n",
    "            \n",
    "            # Attempt to extract the concept using the variable's label or description\n",
    "            description = row['label']  # Or use another column if description is separate\n",
    "            extracted_concepts = extract_concepts_from_description(description)\n",
    "            \n",
    "            if extracted_concepts:\n",
    "                logging.info(f\"Successfully linked Variable: {row['variable_name']} to Concept: {extracted_concepts}\")\n",
    "                child_to_variable.at[index, 'concept'] = extracted_concepts  # Assign the extracted concept\n",
    "            else:\n",
    "                logging.warning(f\"Failed to extract concept for {row['variable_name']}\")\n",
    "    \n",
    "    logging.info(\"Concept extraction process completed\")\n",
    "    return child_to_variable\n",
    "\n",
    "# Actual execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Ensure OpenAI API key is set\n",
    "    if not os.getenv('OPENAI_API_KEY'):\n",
    "        logging.error(\"OpenAI API key not set. Please set the OPENAI_API_KEY environment variable.\")\n",
    "        raise ValueError(\"OpenAI API key is required\")\n",
    "\n",
    "    # Process all data\n",
    "    updated_child_to_variable = extract_missing_concepts(child_to_variable)\n",
    "    \n",
    "    # Save the updated DataFrame\n",
    "    updated_child_to_variable.to_csv('updated_child_to_variable.csv', index=False)\n",
    "    \n",
    "    # Display updated entries\n",
    "    print(\"Concepts successfully populated for missing entries:\")\n",
    "    print(updated_child_to_variable.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdada55-23d5-4b5c-82c8-4584bb1f8caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(child_to_variable[child_to_variable['variable_name'] == 'EMPAVPW_F'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9088c8e-5c1d-4f3a-92f1-349272b61ead",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (graphrag_env)",
   "language": "python",
   "name": "graphrag_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
